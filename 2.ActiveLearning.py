from MCMG import Dataset as Dataset
from MCMG import Training

from rdkit import Chem
from rdkit.Chem import Descriptors
from MCMG import Configuration as Configuration
from MCMG import Generation as Generation
from Utils import filter_smiles_by_properties,expand_smiles_to_5000,get_SA,get_QED

import os
import pandas as pd
import random
import argparse

def expand_smiles_to_10000(smiles_list):
    smiles_list = list(smiles_list)
    if len(smiles_list) >= 10000:
        return random.sample(smiles_list, 10000)
    else:
        result_list = smiles_list.copy()
        while len(result_list) < 10000:
            result_list.extend(smiles_list)
        return random.sample(result_list, 10000)


def get_properties(smile):
    mol = Chem.MolFromSmiles(smile)
    if mol is not None:
        try:
            properties = {
                "MolWt": Descriptors.MolWt(mol),
                "MolLogP": Descriptors.MolLogP(mol),
                "SA": get_SA(mol),  
                "TPSA": Descriptors.TPSA(mol),
                "QED": get_QED(mol)
            }
            return properties
        except:
            return {"MolWt":0,"MolLogP":0,"SA":0,"TPSA":0,"QED":0}
    return {"MolWt":0,"MolLogP":0,"SA":0,"TPSA":0,"QED":0}

def prepare_merged_smiles(filter_smiles):
    if len(filter_smiles) < 5000:
        expanded_smiles = expand_smiles_to_5000(filter_smiles)
        filter_trainset = pd.read_csv("pretrain_DRD2_score_4.csv")["smiles"]
        expanded1_smiles = expand_smiles_to_5000(filter_trainset)
        return expanded1_smiles + expanded_smiles
    else:
        return expand_smiles_to_10000(filter_smiles)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Active Learning Stage")
    parser.add_argument("--fine_tune_dataset", type=str, 
                        default="5_ActiveLearning/training_sets/test-pretrain6_al16_DRD2_第16次微调筛选补全后的1w分子.csv",
                        help="Path to the fine tune dataset")
    parser.add_argument("--output_file", type=str,
                        default="5_ActiveLearning/training_sets/test-pretrain6_al17_DRD2_第17次微调筛选补全后的1w分子.csv",
                        help="Path to save the output filtered dataset")
    args = parser.parse_args()
    base_path = os.getcwd()
    config = Configuration.Config(
        base_path=base_path,
        cycle_prefix="pretrain",
        cycle_suffix="DRD2",
        al_iteration=1,  # use 0 for pretraining
        training_fname="combined_train.csv.gz",
        validation_fname="combined_valid.csv.gz",
        slice_data=None,
        verbose=True, 
    )


    fine_tune_dataset = args.fine_tune_dataset
    # fine_tune_dataset = config.al_train_path + f"{config.cycle_prefix}_al{config.al_iteration-1}_{config.cycle_suffix}"+"_filter.csv"
    print("The loaded dataset is:",fine_tune_dataset)
    al_ds = Dataset.load_data(config=config, 
                            mode="Active Learning",
                            fine_tune_dataset=fine_tune_dataset,
                            desc_path="1_Pretraining/datasets_descriptors/combined_train.yaml")
    config.set_training_parameters(mode="Active Learning", epochs=70)
    model, trainer = Training.train_GPT(
        config=config,
        training_dataset=al_ds,
    )


    print("The molecular generation stage begins.")

    # Load model
    load_path = config.al_weight_path
    load_model_weights = load_path + f"{config.cycle_prefix}_al{config.al_iteration}_{config.cycle_suffix}.pt"
    print("The model loaded during the molecular generation stage is:",load_model_weights)

    config.set_generation_parameters(
        target_number=10000,
        batch_size = 128,
        target_criterion="force_number_unique",
        load_model_weight = load_model_weights,
        dataset_desc_path=config.pretrain_desc_path + config.training_fname.split(".")[0] + ".yaml",   
    )
    molecules_set = Generation.generate_smiles(config) 
    print("End of molecular generation stage.")

    #################################################################################################

    target_properties ={
        "MolWt": {
            "value": 392.91,
            "std_dev": 91.10
        },
        "MolLogP":  {
            "value": 4.05,
            "std_dev": 1.19
        },
        "SA":  {
            "value": 392.91,
            "std_dev": 91.10
        },
        "QED":  {
            "value": 0.63,
            "std_dev": 0.18
        },
        "TPSA":  {
            "value": 45.89,
            "std_dev": 22.98
        },
    }

    filter_smiles = filter_smiles_by_properties(molecules_set, target_properties)
    print("The number of molecules generated by the model is:",len(molecules_set))
    print("The number of molecules after screening is:",len(filter_smiles))
    print("The number of unique molecules after screening:",len(set(filter_smiles)))

    merged_smiles = prepare_merged_smiles(filter_smiles)
    filtered_df = pd.DataFrame({"smiles": list(merged_smiles)})

    filtered_df.to_csv(args.output_file)
    print(f"Filtered dataset saved to: {args.output_file}")

    print("done!")